WORKFLOW

This section briefly describes the workflow in the docker container
that is built from the Dockerfile in 

slurm_sim_tools/docker_files/scw

CALL TREE

 ADDITIONAL SETUP (after the docker image has been set up)
  1. The script /install_files/startup_file.sh is called.
  It starts:
  - rstudio-server
  - sshd
  - mysqld
  using the 'cmd_start' script provided.

  2. The simulation-case specific data must be provided. Such data consists of:
   a. The slubmdbd dump ( usually named <cluster_name>.cfg)
   b. a 'user.sim' file that is used by the simulator. The information 
     contained in this file can be retrieved from the slurmdbd dump.
   c. the data about the jobs being simulated - in a csv format. This is the 
    output of the sacct command.
   d. the data about the QOS, which is output of the sacctmgr command 

   The retrieval of b.,c.,d. is managed by the script 'slurm_conf_setup.sh',
   which in the docker container is placed in /install_files. a. must be
   provided by the sysadmin in all cases. b. is automatically generated from a.
   by 'slurm_conf_setup.sh'. In order to obtain c. and d., the script can use
   two methods:
   A. (recommended)  get c., d. and a. from a tar archive, which needs to be
     copied into the docker container with

     [sudo?] docker cp <tarfile> <container_name>:<location_on_container>

     For the filename and the location, see 'slurm_conf_setup.sh' and
     'variables.env'. At the moment of writing, the docker command used is

     sudo docker cp scw.tar <container_name>:/home/slurm/slurm_sim_ws/slurm_sim_tools/scw/scw.tar

   B. run 2 commands - sacct and saccmgr - via ssh. 

   See script 'slurm_conf_setup.sh' for details.

   RESUME OF POINT 2:
   2.0 Create scw.tar with files a., c. and d.
   2.1 Copy scw.tar into the running container using 'docker cp'
   2.2 run the script /install_files/slurm_conf_setup.sh in the container.

 ACTUAL RUN
  The top-level script is /install_files/initial_test.sh.
  mysql database 'slurm_scwsim' is created and set to be used.
  Then a python, bash and R scripts are called.
  1 scw_cluster_setup.py
   1.1 scw_ws_config.sh
    1.1.1 cp_slurm_conf_dir.py (~180 lines)
      Sets up and configures workspace. Copies the content of the 'etc' 
      directory 
      slurm_sim_ws/slurm_sim_tools/scw/etc
      into a new 'etc' directory
      /slurm_sim_ws/sim/scw/baseline/etc
      and updates contents of some .conf files (slurm.conf, slurmdbd.conf,
      sim.conf) in the new etc (changing only paths)
   1.2 startup slurmdbd
   1.3 populate_slurm_db.sh    
    This step requires:
    1.3.1 : setting up a cluster
    1.3.2 : setting up all the QOSes
    1.3.3 : setting up all the account-QOS-user associations. This is done with
      the 'sacctmgr load' command.
   1.4 generate_job_trace.sh
    A call to the script 
    1.4.1 parse_slurm_output_and_write_trace.R
     This reads the historic job data and. After that,
     A test.trace binary file is generated with a cpp function contained
     in save_trace.cpp (file shamelessly copied in two places).
     The content from test.trace is also saved in csv format in
     test_trace.csv.
  2 run_sim.sh contains a single call to a python script
   2.1 run_sim.py (514 lines). 
     Code is well commented. All is contained in the run_sim function.
    2.1.1 Checks presence of slurm configuration files in location
      specified in the arguments.
    2.1.2 Clears the database from the previous job data (truncates various 
      tables)
    2.1.3 Removes all logfiles
    2.1.4 clears spool (?) and state (content of some directory named 
      like StateSaveLocation and SlurmSpoolDir in slurm.conf
    2.1.5 Checks the dictionaries obtained from slurm.conf, sim.conf and 
      slurmdbd.conf for errors
    2.1.6 Start slurmdbd
    2.1.7 Start slurmctld
      Wait for slurmctld to finish. THE MAGIC HAPPENS HERE!
      Job traces are stored in a file which is set in sim.conf -
      JobsTraceFile (see also slurm_simulator:src/common/sim/sim_conf.c
    2.1.8 Copy files from slurm - defined in slurm.conf - 
      to result directory (named '$pwd/results')
    2.1.9 Process some outputs sprioFileOut and SimStats
  3 Run R scripts to analyse results   
    note: filenames written in R scripts must agree with the ones in 
    slurm.conf
   

JOB TRACES

The history of all the jobs that have executed on the cluster in a period of time is stored in a 'job trace' file, a list of rows 

The job trace file is a .csv file but it has also got a binary representation,
which is the one read by the slurm simulator - the location of the binary trace
file is set in sim.conf, in the JobsTraceFile variable. Each job trace is a
structure of this kind (from slurm_simulator/src/common/sim/sim.h):


typedef struct job_trace {
    int  job_id;
    char *username;
    long int submit; /* relative or absolute? */
    int  duration;
    int  wclimit;
    int  tasks;
    char *qosname;
    char *partition;
    char *account;
    int  cpus_per_task;
    int  tasks_per_node;
    char *reservation;
    char *dependency;
    uint64_t pn_min_memory;/* minimum real memory (in MB) per node OR
     * real memory per CPU | MEM_PER_CPU,
     * NO_VAL use partition default,
     * default=0 (no limit) */
    char *features;
    char *gres;
    int shared;/* 2 if the job can only share nodes with other
     *   jobs owned by that user,
     * 1 if job can share nodes with other jobs,
     * 0 if job needs exclusive access to the node,
     * or NO_VAL to accept the system default.
     * SHARED_FORCE to eliminate user control. */
    long int cancelled; /* time when job should be cancelled, 0 if never */
    struct job_trace *next;
} job_trace_t;


To retrieve the job trace data from the actual slurm system, we need to 
establish a "dictionary" between the csv field names in the job trace file
and sacct options:

CSV field name     - sacct manual entry

 Description of what we need and why
"job_id"           = JobId
"submit"           = Submit
"wclimit"          = Timelimit
"duration"         = // End-Start
"tasks"            = NTasks                                             
"tasks_per_node"   = ?? // int(NTasks/NNodes) ?
"username"         = User
"submit_ts"        = //seems the same as submit but as UNIX time minus 18000sec (it's R conversion from date to integer?)
"qosname"          = QOS
"partition"        = Partition
"account"          = Account
"req_mem"          = ReqMem
"req_mem_per_cpu"  = // can be set to zero, looking at the examples
"features"         = ?? // constraints set with -C or --constraints in sbatch // no info in sacct?
"gres"             = ReqGRES
"shared"           = ?? // there is no info in sacct?  
"cpus_per_task"    = ?? // likely NCPUS/NTasks
"dependency"       = ?? // there is no info in sacct
"cancelled_ts"     = ?? // From State and the End field
#"freq"             = No meaning for slurm, only a check for examples in tutorials

###############################################################################
[This section should match what is written in the 'slurm_conf_setup.sh' script]

Command used to retrieve data from slurm:

sacct --format JobIdRaw,Submit,Timelimit,End,Start,NTasks,NNodes,User,QOS,Partition,Account,ReqMem,ReqGRES,NCPUS,State --allocations --parsable2 --allusers --starttime=092018 --endtime=102018

Notice that starttime and endtime can be changed to select the period of
interest.

Also saccmgr must be queried, in order to get the QOS info. This is the command:

sacctmgr list QOS --parsable2
